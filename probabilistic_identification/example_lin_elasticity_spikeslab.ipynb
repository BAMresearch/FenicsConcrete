{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "parentdir = os.path.dirname(os.path.dirname(os.path.join(os.getcwd(), 'example_lin_elasticity_spikeslab.ipynb')))\n",
    "sys.path.append(parentdir)\n",
    "#print(parentdir)\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import fenicsX_concrete\n",
    "import json #math\n",
    "import pandas as pd\n",
    "#from scipy import optimize\n",
    "\n",
    "with open('test_config.json', 'r') as f: \n",
    "    json_object = json.loads(f.read()) \n",
    "\n",
    "# Adding sensors to the problem definition.\n",
    "def add_sensor(_problem, _dirichlet_bdy, _sensors_num_edge_hor, _sensors_num_edge_ver): \n",
    "    sensor = []\n",
    "    if _dirichlet_bdy == 0: #'left'\n",
    "        for i in range(_sensors_num_edge_hor): \n",
    "            #print((p['length']*(i+1))/_sensors_num_edge_hor) #p['length']\n",
    "            sensor.append(fenicsX_concrete.sensors.DisplacementSensor(np.array([[(p['length']*(i+1))/_sensors_num_edge_hor, 0, 0]]), 'top')) #1/20\n",
    "            sensor.append(fenicsX_concrete.sensors.DisplacementSensor(np.array([[(p['length']*(i+1))/_sensors_num_edge_hor, p['breadth'], 0]]), 'bottom'))\n",
    "        \n",
    "        for i in range(_sensors_num_edge_ver):\n",
    "            #print((p['breadth']*(i+1))/(_sensors_num_edge_ver+1))\n",
    "            sensor.append(fenicsX_concrete.sensors.DisplacementSensor(np.array([[p['length'], (p['breadth']*(i+1))/(_sensors_num_edge_ver+1), 0]]), 'right'))\n",
    "\n",
    "        for i in range(len(sensor)):\n",
    "            _problem.add_sensor(sensor[i])\n",
    "        return len(sensor)\n",
    "    \n",
    "\"\"\" def store_sensor_data(_problem):\n",
    "    mydict = {}\n",
    "    for i in _problem.sensors:\n",
    "       sensor = {i :    \n",
    "        {\"alphabetical_position\" : problem.sensors[i].alphabetical_position,\n",
    "         \"where\" : problem.sensors[i].where[0].tolist(),\n",
    "         \"data\" : problem.sensors[i].data[0].tolist()}\n",
    "        } \n",
    "       mydict.update(sensor)\n",
    "    json_string = json.dumps(mydict , indent = 3)\n",
    "    with open(json_object.get('Data').get('sensor_data'), 'w') as f:\n",
    "        f.write(json_string)  \"\"\"\n",
    "    \n",
    "    \n",
    "def run_test(exp, prob, dirichlet_bdy, load, sensor_flag = 0):\n",
    "    #if dirichlet_bdy == 0:\n",
    "    #    dirichlet_bdy = 'left'\n",
    "    #prob.p.dirichlet_bdy = dirichlet_bdy\n",
    "    #exp.p.dirichlet_bdy = dirichlet_bdy\n",
    "    #prob.p.load = load\n",
    "    #prob.experiment.bcs = prob.experiment.create_displ_bcs(prob.experiment.V)\n",
    "    #prob.apply_neumann_bc()\n",
    "    #prob.calculate_bilinear_form()\n",
    "    prob.solve()\n",
    "    prob.pv_plot(\"Displacement.xdmf\")\n",
    "    #store_sensor_data(prob)\n",
    "    if sensor_flag == 0:\n",
    "        return prob.displacement.x.array\n",
    "    elif sensor_flag == 1 :\n",
    "        counter=0\n",
    "        displacement_at_sensors = np.zeros((len(prob.sensors),2))\n",
    "        for i in prob.sensors:\n",
    "            displacement_at_sensors[counter] = prob.sensors[i].data[-1]\n",
    "            counter += 1\n",
    "        #prob.sensors = fenicsX_concrete.sensors.Sensors()\n",
    "        return displacement_at_sensors#.flatten()\n",
    "\n",
    "def add_noise_to_data(clean_data, no_of_sensors):\n",
    "    #max_disp = np.amax(np.absolute(clean_data))\n",
    "    #min_disp = np.amin(np.absolute(clean_data))\n",
    "    #print('Max', max_disp, 'Min', min_disp)\n",
    "    #if json_object.get('MCMC').get('Error'):\n",
    "    #    return clean_data + np.random.normal(0, 0.01 * min_disp, no_of_sensors) ################################################################\n",
    "    #else:\n",
    "    return clean_data + np.random.normal(0, 1e-5, no_of_sensors)\n",
    "\n",
    "p = fenicsX_concrete.Parameters()  # using the current default values\n",
    "p['bc_setting'] = 'free'\n",
    "p['degree'] = 1\n",
    "p['num_elements_length'] = 25\n",
    "p['num_elements_breadth'] = 5\n",
    "p['dim'] = 2\n",
    "# Uncertainty type:\n",
    "# 0: Constant E and nu fields.\n",
    "# 1: Random E and nu fields.\n",
    "# 2: Linear Springs.\n",
    "# 3: Torsion Springs\n",
    "p['uncertainties'] = [0]\n",
    "#p['k_x'] = 0.5e7\n",
    "#p['k_y'] = 0.5e7\n",
    "\n",
    "p['constitutive'] = 'isotropic' #'orthotropic' \n",
    "p['nu'] = 0.28\n",
    "\n",
    "# Kgmms⁻2/mm², mm, kg, sec, N\n",
    "p['length'] = 1#1000\n",
    "p['breadth'] = 0.05#50\n",
    "\n",
    "p['load'] = [0, -2e7] #[1e3, 0] \n",
    "p['lower_limit'] = 0.9*p['length']\n",
    "p['upper_limit'] = p['length']\n",
    "p['rho'] = 7750 #7750e-9 #kg/mm³\n",
    "p['g'] = 9.81 #9.81e3 #mm/s² for units to be consistent g must be given in m/s².\n",
    "p['E'] = 210e9 #200e6 #Kgmms⁻2/mm² \n",
    "\n",
    "p['dirichlet_bdy'] = 'left'\n",
    "p['body_force'] = False\n",
    "\n",
    "sensors_num_edge_hor = 5\n",
    "sensors_num_edge_ver = 4\n",
    "\n",
    "experiment = fenicsX_concrete.concreteSlabExperiment(p)         # Specifies the domain, discretises it and apply Dirichlet BCs\n",
    "problem = fenicsX_concrete.LinearElasticity(experiment, p)      # Specifies the material law and weak forms.\n",
    "\n",
    "#Adding sensors to the problem definition.\n",
    "test1_sensors_total_num = add_sensor(problem, 0, sensors_num_edge_hor, sensors_num_edge_ver)\n",
    "sensor_positions = np.zeros((test1_sensors_total_num, 3))\n",
    "counter = 0\n",
    "for i in problem.sensors:\n",
    "    sensor_positions[counter] = problem.sensors[i].where[0]\n",
    "    counter += 1\n",
    "\n",
    "#Sparse data (with sensors)\n",
    "\n",
    "temperature_data = np.arange(15, 35, 5) # in degree celsius\n",
    "youngs_modulus = np.zeros(len(temperature_data))\n",
    "data = np.zeros((2*test1_sensors_total_num, len(temperature_data)))\n",
    "for counter, temp in enumerate(temperature_data):\n",
    "    youngs_modulus[counter] = (235 - 0.04 * temp ** 2)*10**9\n",
    "    problem.E.value = youngs_modulus[counter] #Remember problem.p.E is still at its initial value.\n",
    "\n",
    "    #Adding sensors to the problem definition.\n",
    "    #test1_sensors_total_num = add_sensor(problem, 0, sensors_num_edge_hor, sensors_num_edge_ver)\n",
    "    #sensor_positions = np.zeros((test1_sensors_total_num, 3))\n",
    "    #counter = 0\n",
    "    #for i in problem.sensors:\n",
    "    #    sensor_positions[counter] = problem.sensors[i].where[0]\n",
    "    #    counter += 1\n",
    "\n",
    "    test1_data = run_test(experiment, problem, 0, p['load'] , 1)\n",
    "    test1_x_component = add_noise_to_data(test1_data[:,0], test1_sensors_total_num)\n",
    "    test1_y_component = add_noise_to_data(test1_data[:,1], test1_sensors_total_num)\n",
    "\n",
    "    # Data stored in the form of XYXY components.\n",
    "    data[:,counter] = np.vstack((test1_x_component, test1_y_component)).T.flatten()\n",
    "\n",
    "displacement_data = data.flatten('F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################################################\n",
    "##########################################################################################################################################\n",
    "##########################################################################################################################################\n",
    "# Inverse Problem Setup\n",
    "##########################################################################################################################################\n",
    "##########################################################################################################################################\n",
    "##########################################################################################################################################\n",
    "\n",
    "# Loading Prior Distributions from .json File. \n",
    "\n",
    "import json\n",
    "with open('parameters_linear_elasticity.json', 'r') as f: \n",
    "    json_object = json.loads(f.read()) \n",
    "\n",
    "nwalkers = 12\n",
    "ndim = len(json_object.get('parameters')) \n",
    "\n",
    "from scipy.stats import invgamma, halfcauchy, norm, bernoulli, uniform\n",
    "start_parameters = np.zeros((nwalkers, ndim))\n",
    "counter = 0\n",
    "\n",
    "# This loop reads the parameters from the json file and samples from the prior distributions\n",
    "for index, parameter in enumerate(json_object.get('parameters')):\n",
    "    if parameter['prior'][0] == 'Bernoulli':\n",
    "        start_parameters[:, index] = bernoulli.rvs(p = parameter['prior'][1][\"p\"], size=nwalkers)\n",
    "    elif parameter['prior'][0] == 'Spike-Slab':\n",
    "        for hyperparameter in parameter['hyperparameters']:\n",
    "            for ind, param in enumerate(json_object.get('parameters')):\n",
    "                if hyperparameter == param['name']:\n",
    "                    lmbda = start_parameters[:, ind]\n",
    "        start_parameters[:, index] = lmbda*norm.rvs(loc = parameter['prior'][1][\"mean\"], scale = parameter['prior'][1][\"variance\"], size=nwalkers) \n",
    "    elif parameter['prior'][0] == 'Normal': \n",
    "        start_parameters[:, index] = norm.rvs(loc = parameter['prior'][1][\"mean\"], scale = parameter['prior'][1][\"variance\"], size=nwalkers) \n",
    "    elif parameter['prior'][0] == 'Uniform':   \n",
    "        start_parameters[:, index] = uniform.rvs(loc = parameter['prior'][1][\"lower_bound\"], scale = parameter['prior'][1][\"lower_bound\"] + parameter['prior'][1][\"upper_bound\"], size=nwalkers)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the likelihood function\n",
    "\n",
    "def log_likelihood(theta, displacement_data, _sigma):\n",
    "    \n",
    "    youngs_modulus_proposal = theta[0]*np.ones(len(temperature_data)) + theta[1]*temperature_data + theta[2]*np.square(temperature_data)# + theta[3]*np.log(temperature_data) + theta[4]*np.exp(-temperature_data)\n",
    "    if  np.any(youngs_modulus_proposal < 10):\n",
    "        return -np.inf\n",
    "    \n",
    "    #for i in youngs_modulus_proposal:\n",
    "    #    if i < 20:\n",
    "    #        return -np.inf\n",
    "\n",
    "    displacement_model = np.zeros((2*test1_sensors_total_num, len(temperature_data)))\n",
    "    for counter, value in enumerate(youngs_modulus_proposal):\n",
    "        problem.E.value = value*10**9 #Remember problem.p.E is still at its initial value.\n",
    "        test1_data = run_test(experiment, problem, 0, p['load'] , 1)\n",
    "        test1_x_component = add_noise_to_data(test1_data[:,0], test1_sensors_total_num)\n",
    "        test1_y_component = add_noise_to_data(test1_data[:,1], test1_sensors_total_num)\n",
    "        # Data stored in the form of XYXY components.\n",
    "        displacement_model[:,counter] = np.vstack((test1_x_component, test1_y_component)).T.flatten()\n",
    "\n",
    "    displacement_model = displacement_model.flatten('F')\n",
    "\n",
    "    return -0.5 * np.sum((displacement_data - displacement_model) ** 2 / _sigma**2 + np.log(_sigma**2))\n",
    "\n",
    "from scipy.stats import invgamma, halfcauchy, norm, bernoulli\n",
    "\n",
    "\n",
    "\n",
    "def log_prior(theta):\n",
    "    _lp = 0\n",
    "    # This loop reads the parameters from the json file and calulates the log prior.\n",
    "    for index, parameter in enumerate(json_object.get('parameters')):\n",
    "        if parameter['prior'][0] == 'Bernoulli':\n",
    "            ## Uncomment the following lines to see the change in trace of the Bernoulli parameters.\n",
    "            #if theta[index] >= 0.3:    # Trial 1\n",
    "            #    theta[index] = 1\n",
    "            #else:\n",
    "            #    theta[index] = 0\n",
    "            if theta[index] < 0.0 or theta[index] > 1.0:\n",
    "                return -np.inf\n",
    "            _lp += bernoulli.logpmf(0 if theta[index] < 0.5 else 1, p = parameter['prior'][1][\"p\"])            \n",
    "            #_lp += bernoulli.logpmf(theta[index], p = parameter['prior'][1][\"p\"])\n",
    "        elif parameter['prior'][0] == 'Spike-Slab':\n",
    "            for hyperparameter in parameter['hyperparameters']:\n",
    "                for ind, param in enumerate(json_object.get('parameters')):\n",
    "                    if hyperparameter == param['name']:\n",
    "                        lmbda = theta[ind]\n",
    "                        #if lmbda < 0.0 or lmbda > 1.0:\n",
    "                        #    return -np.inf\n",
    "            #_lp += lmbda*norm.logpdf(theta[index], loc = parameter['prior'][1][\"mean\"], scale = parameter['prior'][1][\"variance\"]) \n",
    "            #_lp += lmbda*norm.logpdf(theta[index], loc = parameter['prior'][1][\"mean\"], scale = parameter['prior'][1][\"variance\"])\n",
    "            if lmbda >= 0.5:\n",
    "                _lp += norm.logpdf(theta[index], loc = parameter['prior'][1][\"mean\"], scale = parameter['prior'][1][\"variance\"])\n",
    "            elif lmbda < 0.5:\n",
    "                theta[index] = 0\n",
    "                _lp += 0\n",
    "            #else:\n",
    "            #    return -np.inf\n",
    "        \n",
    "        elif parameter['prior'][0] == 'Normal': \n",
    "            _lp[:, index] = norm.logpdf(theta[index], loc = parameter['prior'][1][\"mean\"], scale = parameter['prior'][1][\"variance\"]) \n",
    "\n",
    "        elif parameter['prior'][0] == 'Uniform':   \n",
    "            _lp[:, index] = uniform.logpdf(theta[index], loc = parameter['prior'][1][\"lower_bound\"], scale = parameter['prior'][1][\"lower_bound\"] + parameter['prior'][1][\"upper_bound\"])    \n",
    "    \n",
    "    return _lp\n",
    "\n",
    "def log_probability(theta, displacement_data, _std_noise):\n",
    "    lp = log_prior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + log_likelihood(theta, displacement_data, _std_noise)\n",
    "\n",
    "std_noise = 1e-4\n",
    "import emcee\n",
    "sampler = emcee.EnsembleSampler(\n",
    "    nwalkers, ndim, log_probability, args=(displacement_data, std_noise))\n",
    "sampler.run_mcmc(start_parameters, 1000, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(ndim, figsize=(10, 7), sharex=True)\n",
    "samples = sampler.get_chain()\n",
    "labels = [\"lmbda_a\", \"a\", \"lmbda_b\", \"b\", \"lmbda_c\", \"c\"] # Change the labels over here if changes in parameters are made in json file.\n",
    "for i in range(ndim):\n",
    "    ax = axes[i]\n",
    "    ax.plot(samples[:, :, i], \"k\", alpha=0.3)\n",
    "    ax.set_xlim(0, len(samples))\n",
    "    ax.set_ylabel(labels[i])\n",
    "    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "\n",
    "axes[-1].set_xlabel(\"step number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "flat_samples = sampler.get_chain(discard=500, thin=15, flat=True)\n",
    "print(flat_samples.shape)\n",
    "import corner\n",
    "labels = [\"lmbda_a\", \"a\", \"lmbda_b\", \"b\", \"lmbda_c\", \"c\"]  # Change the labels over here if changes in parameters are made in json file.\n",
    "fig = corner.corner(\n",
    "    flat_samples, labels=labels, truths=[1, 235, 0, 0, 1, -0.04]\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fenicsxclone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
